import numpy as np
import time
from numba import cuda

# Importaciones de la L√≥gica (NO se modifica la l√≥gica de c√°lculo aqu√≠)
from .ops import matrix_mult_cpu
from .kernels import run_matrix_mult_gpu

def crear_matrices(N):
    """Utilidad simple para crear matrices."""
    np.random.seed(42)
    A = np.random.rand(N, N).astype(np.float32)
    B = np.random.rand(N, N).astype(np.float32)
    return A, B

def run_compilacion():
    """
    Ejecuta la demostraci√≥n, mostrando expl√≠citamente el proceso de compilaci√≥n 
    (JIT, Transferencia y Mapeo Loop-to-Grid) y la comparaci√≥n de rendimiento.
    """
    
    # Configuraci√≥n de tama√±o de matriz (grande para forzar la diferencia)
    MATRIX_SIZE = 512 
    THREADS_PER_BLOCK = (32, 32)
    
    print("="*80)
    print("  PROYECTO: COMPILACI√ìN PARA GPU Y MODELOS DE EJECUCI√ìN MASIVA")
    print("  Demostraci√≥n del Proceso de Traducci√≥n y Paralelismo Expl√≠cito")
    print("="*80)

    # Inicializaci√≥n de datos
    A, B = crear_matrices(MATRIX_SIZE)
    total_threads_needed = MATRIX_SIZE * MATRIX_SIZE
    
    print(f"\nüìä Configuraci√≥n:")
    print(f"  - Matriz de C√≥mputo (N): {MATRIX_SIZE}x{MATRIX_SIZE}")
    print(f"  - L√≥gica Secuencial (CPU): 3 ciclos anidados (O(N¬≥))")
    print(f"  - L√≥gica Paralela (GPU): {total_threads_needed:,} hilos de ejecuci√≥n.")
    
    # --- 1. EJECUCI√ìN SECUENCIAL (CPU) ---
    print("\n" + "="*80)
    print("--- 1. Fase Secuencial (CPU) ---")
    print("="*80)
    print("-> Ejecutando L√≥gica de Alto Nivel (matrix_mult_cpu)...")
    C_cpu, tiempo_cpu_seq = matrix_mult_cpu(A, B)
    print(f"‚è±Ô∏è  Tiempo de Ejecuci√≥n (CPU Pura): {tiempo_cpu_seq:.4f} segundos")
    print("   (Esto demuestra la ineficiencia que el compilador debe resolver.)")

    # --- 2. EJECUCI√ìN PARALELA (GPU) - PROCESO DE COMPILACI√ìN ---
    try:
        if not cuda.is_available():
            print("\n‚ùå ERROR: No se detect√≥ una GPU compatible con CUDA. No se puede continuar.")
            return

        print("\n" + "="*80)
        print("--- 2. Fase de Compilaci√≥n y Ejecuci√≥n GPU ---")
        print("="*80)

        # A) COMPILACI√ìN JIT (Warm-up)
        print("A) COMPILACI√ìN JIT (Python -> PTX):")
        start_jit = time.time()
        # Se invoca el Kernel por primera vez. Numba traduce el c√≥digo Python a PTX (IR).
        run_matrix_mult_gpu(A[:1,:1], B[:1,:1], threads_per_block=(1, 1)) 
        tiempo_jit_warmup = time.time() - start_jit
        print(f"   ‚úì Compilador Numba JIT activado, PTX (IR) generado y cacheado. (Tiempo: {tiempo_jit_warmup:.4f}s)")
        
        # B) TRANSFERENCIA (Desaf√≠o de Arquitectura Heterog√©nea)
        print("\nB) TRANSFERENCIA HOST -> DEVICE:")
        # La funci√≥n run_matrix_mult_gpu ya mide esto internamente.
        print("   -> Se mueven los datos de la memoria HOST (CPU) a la memoria DEVICE (GPU)...")
        
        # C) EJECUCI√ìN DEL KERNEL (Mapeo Loop-to-Grid)
        print("\nC) MAPEO ESPACIAL Y EJECUCI√ìN (SIMT):")
        print(f"   -> El compilador rompe los bucles y asigna la tarea a {total_threads_needed:,} hilos concurrentes...")
        
        C_gpu, tiempo_gpu_total, tiempo_gpu_kernel, tiempo_transfer = run_matrix_mult_gpu(A, B, threads_per_block=THREADS_PER_BLOCK)

        print(f"   ‚è±Ô∏è  Tiempo C√≥mputo Kernel (Puro): {tiempo_gpu_kernel:.4f} segundos")
        print(f"   ‚è±Ô∏è  Tiempo Transferencias (Overhead): {tiempo_transfer:.4f} segundos")
        print(f"   ‚è±Ô∏è  Tiempo TOTAL GPU: {tiempo_gpu_total:.4f} segundos")
        
        # --- 3. AN√ÅLISIS DE RESULTADOS ---
        print("\n" + "="*80)
        print("--- 3. Resultados y An√°lisis de la Transformaci√≥n ---")
        print("="*80)
        
        speedup_kernel_vs_seq = tiempo_cpu_seq / tiempo_gpu_kernel
        
        print(f"\n| {'M√©trica':<35} | {'Valor':<10} | {'An√°lisis':<30} |")
        print("|" + "-"*36 + "|" + "-"*12 + "|" + "-"*32 + "|")
        print(f"| {'Tiempo CPU (L√≥gica Secuencial)':<35} | {tiempo_cpu_seq:<12.4f} | {'Base de comparaci√≥n'}")
        print(f"| {'Tiempo GPU (Kernel Puro)':<35} | {tiempo_gpu_kernel:<12.4f} | {'C√≥mputo tras Mapeo Loop-to-Grid'}")
        print(f"| {'Speedup (Kernel vs CPU)':<35} | {f'{speedup_kernel_vs_seq:.2f}x':<12} | {f'Aceleraci√≥n por Paralelismo Expl√≠cito'}")

        # Validaci√≥n
        valid = np.allclose(C_cpu, C_gpu, atol=1e-5)
        print(f"\n‚úì Validaci√≥n (CPU vs GPU): {'COINCIDEN' if valid else 'FALLA'} - Demuestra la precisi√≥n de la traducci√≥n JIT.")
        
    except Exception as e:
        print(f"\n‚ùå [ERROR en GPU]: {e}")
        print("Verifique su entorno CUDA y la instalaci√≥n de Numba.")
    
    print("\n" + "="*80)
    print("  FIN DE LA DEMOSTRACI√ìN EXPL√çCITA")
    print("="*80)